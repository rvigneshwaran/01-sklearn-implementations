{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "diabetes_df = pd.DataFrame(data=np.c_[diabetes['data'], diabetes['target']],\n",
    "                            columns=np.append(diabetes['feature_names'], 'target'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and feature engineering\n",
    "features = diabetes['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(diabetes_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a VotingRegressor model with hyperparameter tuning\n",
    "def train_voting_regressor(X_train, y_train):\n",
    "    # Define individual regressors\n",
    "    reg1 = RandomForestRegressor(random_state=42)\n",
    "    reg2 = GradientBoostingRegressor(random_state=42)\n",
    "    reg3 = LinearRegression()\n",
    "\n",
    "    # Hyperparameter tuning for RandomForestRegressor\n",
    "    param_grid_rf = {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "    grid_rf = GridSearchCV(reg1, param_grid_rf, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    best_rf = grid_rf.best_estimator_\n",
    "\n",
    "    # Hyperparameter tuning for GradientBoostingRegressor\n",
    "    param_grid_gb = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "    grid_gb = GridSearchCV(reg2, param_grid_gb, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_gb.fit(X_train, y_train)\n",
    "    best_gb = grid_gb.best_estimator_\n",
    "\n",
    "    # Create a VotingRegressor\n",
    "    voting_regressor = VotingRegressor(estimators=[('rf', best_rf), ('gb', best_gb), ('lr', reg3)])\n",
    "    voting_regressor.fit(X_train, y_train)\n",
    "    return voting_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions with test data\n",
    "def make_predictions(model, X_test, features):\n",
    "    predictions = model.predict(X_test)\n",
    "    results_df = pd.DataFrame({'Actual': test_data['target'].values, 'Predicted': predictions})\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "X_train, y_train = train_data[features], train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a VotingRegressor model\n",
    "voting_regressor = train_voting_regressor(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the model on the test set: 2780.82\n",
      "R2 Score of the model on the test set: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "X_test, y_test = test_data[features], test_data['target']\n",
    "mse, r2 = evaluate_model(voting_regressor, X_test, y_test)\n",
    "print(f'Mean Squared Error of the model on the test set: {mse:.2f}')\n",
    "print(f'R2 Score of the model on the test set: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Predictions:\n",
      "    Actual   Predicted\n",
      "0    219.0  146.480651\n",
      "1     70.0  181.877911\n",
      "2    202.0  148.123559\n",
      "3    230.0  271.076975\n",
      "4    111.0  118.813435\n",
      "..     ...         ...\n",
      "84   153.0   96.518567\n",
      "85    98.0   74.212735\n",
      "86    37.0   86.185781\n",
      "87    63.0   73.132624\n",
      "88   184.0  162.048681\n",
      "\n",
      "[89 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with test data\n",
    "results_df = make_predictions(voting_regressor, X_test, features)\n",
    "print('\\nTest Data Predictions:')\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
